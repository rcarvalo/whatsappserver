#!/usr/bin/env python3
"""
ğŸ¤– DÃ©monstration de l'Extracteur LLM de Montres
Exemples d'utilisation et cas d'usage avancÃ©s
"""

import os
import sys
import json
from datetime import datetime
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Ajouter le dossier src au path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

def demo_basic_extraction():
    """DÃ©monstration de l'extraction basique"""
    
    print("ğŸ¤– DÃ‰MONSTRATION - Extracteur LLM Basique")
    print("=" * 50)
    
    try:
        from src.llm_watch_extractor import LLMWatchExtractor
        
        # Initialiser l'extracteur
        extractor = LLMWatchExtractor(openai_api_key=os.getenv('OPENAI_API_KEY'))
        
        # Messages d'exemple
        messages = [
            "Je vends ma Rolex Submariner Date 116610LN, Ã©tat neuf avec boÃ®te et papiers. Prix: 9500â‚¬",
            "Cherche Omega Speedmaster Professional Moonwatch, budget max 4000â‚¬",
            "Quelqu'un connaÃ®t la cote d'une Patek Philippe Nautilus ?",
            "URGENT! Daytona Panda 116500LN disponible, 28kâ‚¬ nÃ©gociable",
            "Ma collection se sÃ©pare: PP 5711, AP 15400, Rolex Hulk - Prix sur demande"
        ]
        
        for i, message in enumerate(messages, 1):
            print(f"\nğŸ“± MESSAGE {i}: {message}")
            
            # Extraction
            result = extractor.extract_watch_info(message)
            
            print(f"ğŸ¤– EXTRACTION:")
            print(f"   Marque: {result.brand}")
            print(f"   ModÃ¨le: {result.model}")
            print(f"   Prix: {result.price} {result.currency}")
            print(f"   Type: {result.message_type}")
            print(f"   Confiance: {result.confidence_score:.2f}")
            
            if result.llm_reasoning:
                print(f"   Raisonnement: {result.llm_reasoning[:80]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def demo_advanced_extraction():
    """DÃ©monstration avec mÃ©tadonnÃ©es WhatsApp"""
    
    print("\nğŸ¯ DÃ‰MONSTRATION - Extraction avec Contexte WhatsApp")
    print("=" * 55)
    
    try:
        from src.llm_watch_extractor import LLMWatchExtractor
        
        extractor = LLMWatchExtractor(openai_api_key=os.getenv('OPENAI_API_KEY'))
        
        # Message avec contexte
        message = "Les gars, ma Hulk est dispo si Ã§a intÃ©resse quelqu'un. Ã‰tat impec, full set. 12.5k"
        
        # MÃ©tadonnÃ©es WhatsApp enrichies
        metadata = {
            'sender_profile_name': 'Groupe Rolex Passion France',
            'sender_formatted_name': 'Pierre M.',
            'is_group_message': True,
            'group_context_indicators': ['groupe', 'passion'],
            'semantic_metadata': {
                'intent_signals': {
                    'is_selling': True,
                    'is_greeting': True,
                    'has_urgency': False
                },
                'text_analysis': {
                    'language_hints': ['french'],
                    'has_price': True,
                    'word_count': len(message.split())
                },
                'timing': {
                    'is_business_hours': True
                }
            }
        }
        
        print(f"ğŸ“± MESSAGE: {message}")
        print(f"ğŸ¢ CONTEXTE: Groupe '{metadata['sender_profile_name']}'")
        
        # Extraction avec contexte
        result = extractor.extract_watch_info(message, metadata)
        
        print(f"\nğŸ¤– EXTRACTION ENRICHIE:")
        print(f"   Marque: {result.brand}")
        print(f"   ModÃ¨le: {result.model}")
        print(f"   Collection: {result.collection}")
        print(f"   Prix: {result.price} {result.currency}")
        print(f"   Type de prix: {result.price_type}")
        print(f"   Condition: {result.condition}")
        print(f"   BoÃ®te: {'Oui' if result.has_box else 'Non' if result.has_box is False else 'Non mentionnÃ©'}")
        print(f"   Papiers: {'Oui' if result.has_papers else 'Non' if result.has_papers is False else 'Non mentionnÃ©'}")
        print(f"   Type message: {result.message_type}")
        print(f"   NÃ©gociable: {'Oui' if result.negotiable else 'Non' if result.negotiable is False else 'Non prÃ©cisÃ©'}")
        print(f"   Confiance: {result.confidence_score:.2f}")
        
        print(f"\nğŸ§  RAISONNEMENT LLM:")
        print(f"   {result.llm_reasoning}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def demo_batch_extraction():
    """DÃ©monstration d'extraction par lots"""
    
    print("\nâš¡ DÃ‰MONSTRATION - Extraction par Lots")
    print("=" * 45)
    
    try:
        from src.llm_watch_extractor import LLMWatchExtractor
        
        extractor = LLMWatchExtractor(openai_api_key=os.getenv('OPENAI_API_KEY'))
        
        # Messages multiples
        batch_messages = [
            {
                'content': 'Vends Rolex GMT Master II 126710BLRO, Ã©tat neuf, 14000â‚¬',
                'metadata': {'sender_profile_name': 'Jean Dupont'}
            },
            {
                'content': 'Omega Seamaster Planet Ocean 600m, orange, 3500â‚¬',
                'metadata': {'sender_profile_name': 'Marc L.'}
            },
            {
                'content': 'ISO: Patek Philippe Aquanaut, budget flexible',
                'metadata': {'sender_profile_name': 'Collectionneur_Paris'}
            }
        ]
        
        print(f"ğŸ“¦ Traitement de {len(batch_messages)} messages...")
        
        # Extraction par lot
        results = extractor.extract_batch(batch_messages)
        
        for i, (message, result) in enumerate(zip(batch_messages, results), 1):
            print(f"\nğŸ“± MESSAGE {i}: {message['content'][:50]}...")
            print(f"   Marque: {result.brand}")
            print(f"   ModÃ¨le: {result.model}")
            print(f"   Prix: {result.price}")
            print(f"   Type: {result.message_type}")
            print(f"   Confiance: {result.confidence_score:.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def demo_statistics_and_cache():
    """DÃ©monstration des statistiques et du cache"""
    
    print("\nğŸ“Š DÃ‰MONSTRATION - Statistiques et Cache")
    print("=" * 45)
    
    try:
        from src.llm_watch_extractor import LLMWatchExtractor
        
        extractor = LLMWatchExtractor(openai_api_key=os.getenv('OPENAI_API_KEY'))
        
        # Plusieurs extractions pour gÃ©nÃ©rer des stats
        test_messages = [
            "Rolex Daytona acier, 25000â‚¬",
            "Omega Speedmaster, parfait Ã©tat, 4000â‚¬",
            "Cherche Patek Philippe Nautilus",
            "Tudor Black Bay, quasi neuve, 2800â‚¬"
        ]
        
        print("âš¡ Extraction de messages pour statistiques...")
        
        for message in test_messages:
            extractor.extract_watch_info(message)
        
        # Test du cache (mÃªme message)
        print(f"\nğŸ”„ Test du cache...")
        start_time = datetime.now()
        extractor.extract_watch_info(test_messages[0])  # DÃ©jÃ  en cache
        cache_time = (datetime.now() - start_time).total_seconds()
        print(f"   Temps avec cache: {cache_time:.3f}s")
        
        # Statistiques
        stats = extractor.get_extraction_stats()
        print(f"\nğŸ“ˆ STATISTIQUES D'EXTRACTION:")
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        
        # Nettoyage du cache
        extractor.clear_cache()
        print(f"\nğŸ§¹ Cache vidÃ©")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def demo_complex_scenarios():
    """ScÃ©narios complexes pour tester les limites"""
    
    print("\nğŸ­ DÃ‰MONSTRATION - ScÃ©narios Complexes")
    print("=" * 45)
    
    try:
        from src.llm_watch_extractor import LLMWatchExtractor
        
        extractor = LLMWatchExtractor(openai_api_key=os.getenv('OPENAI_API_KEY'))
        
        complex_scenarios = [
            {
                'name': 'Message avec fautes',
                'content': 'salu jvend ma rolex submariner hulk etat impecable boite papier 12500e negociable'
            },
            {
                'name': 'Multiples montres',
                'content': 'Je vends ma collection: Rolex Sub (8kâ‚¬), Omega Speedmaster (4kâ‚¬), Tudor BB58 (3kâ‚¬)'
            },
            {
                'name': 'Jargon technique',
                'content': 'Daytona 116500LN Panda, movement 4130, ceramic bezel, COSC certified, AD purchased'
            },
            {
                'name': 'Message Ã©motionnel',
                'content': 'ğŸ˜¢ Je dois me sÃ©parer de ma Nautilus 5711/1A bleue... Prix de marchÃ© actuel 150kâ‚¬ mais je cherche collectionneur sÃ©rieux'
            }
        ]
        
        for scenario in complex_scenarios:
            print(f"\nğŸ¯ {scenario['name'].upper()}:")
            print(f"   Message: {scenario['content']}")
            
            result = extractor.extract_watch_info(scenario['content'])
            
            print(f"   ğŸ¤– RÃ©sultat:")
            print(f"      Marque: {result.brand}")
            print(f"      ModÃ¨le: {result.model}")
            print(f"      Prix: {result.price}")
            print(f"      Type: {result.message_type}")
            print(f"      Confiance: {result.confidence_score:.2f}")
            
            if result.confidence_score > 0.7:
                print(f"      âœ… Extraction de haute qualitÃ©")
            elif result.confidence_score > 0.4:
                print(f"      âš ï¸ Extraction acceptable")
            else:
                print(f"      âŒ Extraction incertaine")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def main():
    """Fonction principale de dÃ©monstration"""
    
    print("ğŸ¤– SUITE COMPLÃˆTE DE DÃ‰MONSTRATIONS - Extracteur LLM")
    print("=" * 65)
    print("Cette dÃ©mo montre toutes les capacitÃ©s de l'extracteur LLM")
    print("pour l'analyse prÃ©cise des messages de vente de montres")
    print("=" * 65)
    
    success = True
    
    # VÃ©rifier la clÃ© API
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ OPENAI_API_KEY non configurÃ©e")
        print("Configurer la variable d'environnement pour exÃ©cuter cette dÃ©mo")
        return False
    
    # DÃ©monstrations
    demos = [
        ("Extraction basique", demo_basic_extraction),
        ("Extraction avec contexte", demo_advanced_extraction),
        ("Extraction par lots", demo_batch_extraction),
        ("Statistiques et cache", demo_statistics_and_cache),
        ("ScÃ©narios complexes", demo_complex_scenarios)
    ]
    
    for demo_name, demo_func in demos:
        print(f"\nğŸ¬ Lancement: {demo_name}")
        if not demo_func():
            print(f"âŒ Ã‰chec de la dÃ©mo: {demo_name}")
            success = False
        else:
            print(f"âœ… SuccÃ¨s de la dÃ©mo: {demo_name}")
    
    print("\n" + "=" * 65)
    if success:
        print("ğŸ‰ TOUTES LES DÃ‰MONSTRATIONS RÃ‰USSIES!")
        print("\nğŸ’¡ AVANTAGES DE L'EXTRACTEUR LLM:")
        print("   ğŸ¯ PrÃ©cision supÃ©rieure aux regex")
        print("   ğŸ§  ComprÃ©hension du contexte et des nuances")
        print("   ğŸŒ Gestion des fautes d'orthographe et du jargon")
        print("   ğŸ“Š Classification automatique des intentions")
        print("   ğŸ” Extraction d'informations complexes")
        print("   âš¡ Cache intelligent pour optimiser les performances")
        print("   ğŸ“ˆ Statistiques et monitoring intÃ©grÃ©s")
        print("\nğŸš€ Votre systÃ¨me WhatsApp RAG est prÃªt pour la production!")
    else:
        print("âŒ CERTAINES DÃ‰MONSTRATIONS ONT Ã‰CHOUÃ‰")
        print("VÃ©rifier la configuration des API keys")
    
    print("=" * 65)

if __name__ == "__main__":
    main()
